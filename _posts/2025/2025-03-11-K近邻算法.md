---
title: K近邻算法：从原理到实践的完整指南
date: 2025-03-11 21:30:00 +0800
categories: [机器学习]
tags: [监督学习, K近邻算法, KNeighbors, Python]
description: 深入浅出地讲解K近邻算法的原理、实现与应用
image: /assets/2025/03/image_kneighbors.png
---
## K近邻算法简介

K近邻是一种监督学习算法。它的思路是针对给定的一组数据点，通过检查离一个新点最近的点来预测其标签。


### 算法原理

如果是回归问题，每个数据点的特征由x和y坐标决定，这意味着给定一个x坐标，为了预测它的y是什么，可以找到离x最近的n个点，然后对它们的y求平均。

如果是分类问题，找到与想要预测的类别的点最近的n个点，并选择出现次数最多的类别。

本质是找出与目标点相似的数据点，用它们对目标点进行回归分类。常见的确定K近邻的方法有：
1. y 值
2. 欧氏距离
3. 曼哈顿距离
4. 明氏距离
5. 使用权重：较近的点比较远的点对结果的贡献更大
6. 半径邻居：选择给定半径内的所有邻居，而不是找到最近的n个邻居

### 算法特点

## 实战示例

Scikit-Learn 提供了 KNeighborsRegressor 和 KNeighborsClassifier 类来实现K近邻学习算法训练回归和分类模型；同时，也提供了 RadiusKNeighborsRegressor 和 RadiusKNeighborsClassifier 类来接受半径而不是邻居数量作为参数。

### 使用K近邻对花卉进行分类

我们使用 Scikit-Learn 自带的鸢（yuan）尾花数据集。

```python
import pandas as pd
from sklearn.datasets import load_iris

iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['class'] = iris.target
# df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)
df['class name'] = iris.target_names[df['class']]
df.head()
```

![数据集](/assets/2025/03/kneighbors-output1.jpeg)

接下来我们需要把数据集分成两个部分，一个用于训练模型，一个用于测试模型效果。
我们采取80/20的比例分割数据集。

> 用于训练的数据越多，模型就越准确；而用于测试的数据越多，在衡量模型的准确性时我们就越有信心。
{: .prompt-tip }

```python
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2)
```

下一步是训练一个机器学习模型。

调用fit方法使模型拟合到数据，从而完成对它的训练。

```python
from sklearn.neighbors import KNeighborsClassifier

# 建模并预测
knn = KNeighborsClassifier()
knn.fit(x_train, y_train)
```

> 你可能会发现上述训练过程很快，这是因为KNeighborsClassifier在fit阶段只会构建一个二叉树来加快相邻样本的查找过程，而不是训练模型。
{: .prompt-info }

最后一步是使用从原始数据集中分割出来的测试数据来衡量模型的准确率。

```python
score = knn.score(x_test, y_test)
print(score)
```

此时，我们可以看到score返回0.9666666666666667。

在 Scikit-Learn 中，我们可以通过调用predict方法来进行预测。结果0代表为山鸢尾，1代表为变色鸢尾，2代表为维吉尼亚鸢尾。

```python
y_pred = knn.predict([[5.1, 3.5, 1.4, 0.2]])
print(y_pred)
```

默认情况下 KNeighborsClassifier 采用的邻居数量为5，可以像下面这样指定邻居的数量：

```python
knn = KNeighborsClassifier(n_neighbors=10)
```